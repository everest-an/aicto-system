#!/usr/bin/env python3
"""
AI PM CLI - æ™ºèƒ½ç«å“åˆ†æå‘½ä»¤è¡Œå·¥å…·
é›†æˆç«å“é‡‡é›†ã€åˆ†æå’Œå»ºè®®ç”ŸæˆåŠŸèƒ½
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from competitor_collector import CompetitorCollector
from competitor_analyzer import CompetitorAnalyzer


def cmd_discover(args):
    """å‘ç°ç«å“å‘½ä»¤"""
    print("ğŸ” ç«å“å‘ç°åŠŸèƒ½")
    collector = CompetitorCollector(data_dir=args.data_dir)
    
    competitors = collector.discover_competitors(
        product_description=args.description,
        keywords=args.keywords.split(',') if args.keywords else []
    )
    
    print(f"\nå‘ç°çš„ç«å“:")
    for i, comp in enumerate(competitors, 1):
        print(f"  {i}. {comp}")


def cmd_collect(args):
    """é‡‡é›†ç«å“ä¿¡æ¯å‘½ä»¤"""
    print("ğŸ“Š ç«å“ä¿¡æ¯é‡‡é›†")
    collector = CompetitorCollector(data_dir=args.data_dir)
    
    if args.config:
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        import json
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
        competitors = collector.collect_batch(config)
    else:
        # å•ä¸ªç«å“é‡‡é›†
        competitor = collector.collect_competitor_info(
            name=args.name,
            website=args.website,
            github_repo=args.github
        )
        collector.save_competitor(competitor)
        competitors = [competitor]
    
    print(f"\nâœ… æˆåŠŸé‡‡é›† {len(competitors)} ä¸ªç«å“çš„ä¿¡æ¯")


def cmd_analyze(args):
    """åˆ†æç«å“å‘½ä»¤"""
    print("ğŸ§  ç«å“æ™ºèƒ½åˆ†æ")
    analyzer = CompetitorAnalyzer(
        data_dir=args.data_dir,
        output_dir=args.output_dir
    )
    
    # å®šä¹‰æˆ‘ä»¬çš„äº§å“
    our_product_description = args.our_description or "AI PMç›‘ç£ç³»ç»Ÿ - å®šåˆ¶åŒ–çš„AIå¼€å‘ç›‘ç£å’Œä»£ç å®¡æŸ¥å·¥å…·"
    
    # å®šä¹‰æˆ‘ä»¬çš„åŠŸèƒ½
    our_features = [
        {"name": "GitHub Actionsé›†æˆ", "description": "è‡ªåŠ¨è¿è¡Œç›‘ç£æ£€æŸ¥", "category": "core"},
        {"name": "ä»£ç è´¨é‡æ£€æŸ¥", "description": "æ£€æŸ¥ä»£ç å¤æ‚åº¦å’Œè§„èŒƒ", "category": "core"},
        {"name": "æ•æ„Ÿä¿¡æ¯é˜²æŠ¤", "description": "é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²", "category": "core"},
        {"name": "è‡ªåŠ¨éƒ¨ç½²", "description": "åŠŸèƒ½å®Œæˆåè‡ªåŠ¨éƒ¨ç½²", "category": "advanced"},
        {"name": "ä¸»åŠ¨é—®é¢˜å‘ç°", "description": "è‡ªåŠ¨å‘ç°ä»£ç ä¸­çš„æ½œåœ¨é—®é¢˜", "category": "advanced"}
    ]
    
    # æ‰§è¡Œåˆ†æ
    report = analyzer.analyze_all_competitors(our_product_description, our_features)
    
    # ä¿å­˜æŠ¥å‘Š
    analyzer.save_report(report, filename=args.output)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    if args.markdown:
        md_report = analyzer.generate_markdown_report(report)
        md_path = Path(args.output_dir) / args.output.replace('.json', '.md')
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_report)
        print(f"ğŸ“„ MarkdownæŠ¥å‘Š: {md_path}")


def cmd_report(args):
    """æŸ¥çœ‹åˆ†ææŠ¥å‘Šå‘½ä»¤"""
    print("ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š")
    
    import json
    report_path = Path(args.output_dir) / args.report
    
    if not report_path.exists():
        print(f"âŒ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_path}")
        return
    
    with open(report_path, 'r', encoding='utf-8') as f:
        report = json.load(f)
    
    print(f"\nåˆ†ææ—¶é—´: {report['analysis_date']}")
    print(f"ç«å“æ•°é‡: {report['competitors_analyzed']}")
    print(f"åŠŸèƒ½å·®è·: {report['total_gaps']}")
    print(f"è¿­ä»£å»ºè®®: {report['total_suggestions']}")
    print(f"é«˜ä¼˜å…ˆçº§: {report['high_priority_suggestions']}")
    
    if args.suggestions:
        print(f"\nğŸ¯ é«˜ä¼˜å…ˆçº§å»ºè®® (å‰{args.suggestions}æ¡):")
        for i, sugg in enumerate(report['suggestions'][:args.suggestions], 1):
            print(f"\n{i}. {sugg['title']}")
            print(f"   æ¥æº: {sugg['source_competitor']}")
            print(f"   ä¼˜å…ˆçº§: {sugg['priority']}/5")
            print(f"   å½±å“: {sugg['impact']} | éš¾åº¦: {sugg['effort']}")
            print(f"   æè¿°: {sugg['description']}")


def cmd_list(args):
    """åˆ—å‡ºå·²é‡‡é›†çš„ç«å“"""
    print("ğŸ“‹ å·²é‡‡é›†çš„ç«å“")
    collector = CompetitorCollector(data_dir=args.data_dir)
    
    competitors = collector.list_competitors()
    
    if not competitors:
        print("   (æš‚æ— æ•°æ®)")
        return
    
    print(f"\nå…± {len(competitors)} ä¸ªç«å“:")
    for i, comp_id in enumerate(competitors, 1):
        competitor = collector.load_competitor(comp_id)
        if competitor:
            print(f"  {i}. {competitor.name}")
            print(f"     ID: {competitor.id}")
            print(f"     ç½‘ç«™: {competitor.website}")
            print(f"     åŠŸèƒ½æ•°: {len(competitor.features)}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='AI PM CLI - æ™ºèƒ½ç«å“åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å‘ç°ç«å“
  %(prog)s discover --description "AIä»£ç å®¡æŸ¥å·¥å…·" --keywords "ai,code review"
  
  # é‡‡é›†ç«å“ä¿¡æ¯
  %(prog)s collect --name "CodeRabbit" --website "https://coderabbit.ai"
  
  # æ‰¹é‡é‡‡é›†
  %(prog)s collect --config competitors.json
  
  # åˆ†æç«å“
  %(prog)s analyze --markdown
  
  # æŸ¥çœ‹æŠ¥å‘Š
  %(prog)s report --suggestions 5
  
  # åˆ—å‡ºå·²é‡‡é›†çš„ç«å“
  %(prog)s list
"""
    )
    
    parser.add_argument('--data-dir', default='./data/competitors',
                       help='ç«å“æ•°æ®ç›®å½• (é»˜è®¤: ./data/competitors)')
    parser.add_argument('--output-dir', default='./data/analysis',
                       help='åˆ†æè¾“å‡ºç›®å½• (é»˜è®¤: ./data/analysis)')
    
    subparsers = parser.add_subparsers(dest='command', help='å­å‘½ä»¤')
    
    # discoverå‘½ä»¤
    discover_parser = subparsers.add_parser('discover', help='å‘ç°ç«å“')
    discover_parser.add_argument('--description', required=True, help='äº§å“æè¿°')
    discover_parser.add_argument('--keywords', help='å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰')
    
    # collectå‘½ä»¤
    collect_parser = subparsers.add_parser('collect', help='é‡‡é›†ç«å“ä¿¡æ¯')
    collect_parser.add_argument('--name', help='ç«å“åç§°')
    collect_parser.add_argument('--website', help='ç«å“ç½‘ç«™')
    collect_parser.add_argument('--github', help='GitHubä»“åº“URL')
    collect_parser.add_argument('--config', help='æ‰¹é‡é‡‡é›†é…ç½®æ–‡ä»¶ï¼ˆJSONï¼‰')
    
    # analyzeå‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='åˆ†æç«å“')
    analyze_parser.add_argument('--our-description', help='æˆ‘ä»¬äº§å“çš„æè¿°')
    analyze_parser.add_argument('--output', default='analysis_report.json',
                               help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: analysis_report.json)')
    analyze_parser.add_argument('--markdown', action='store_true',
                               help='åŒæ—¶ç”ŸæˆMarkdownæŠ¥å‘Š')
    
    # reportå‘½ä»¤
    report_parser = subparsers.add_parser('report', help='æŸ¥çœ‹åˆ†ææŠ¥å‘Š')
    report_parser.add_argument('--report', default='analysis_report.json',
                              help='æŠ¥å‘Šæ–‡ä»¶å (é»˜è®¤: analysis_report.json)')
    report_parser.add_argument('--suggestions', type=int, default=5,
                              help='æ˜¾ç¤ºå»ºè®®æ•°é‡ (é»˜è®¤: 5)')
    
    # listå‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºå·²é‡‡é›†çš„ç«å“')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # æ‰§è¡Œå¯¹åº”çš„å‘½ä»¤
    commands = {
        'discover': cmd_discover,
        'collect': cmd_collect,
        'analyze': cmd_analyze,
        'report': cmd_report,
        'list': cmd_list
    }
    
    try:
        commands[args.command](args)
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
